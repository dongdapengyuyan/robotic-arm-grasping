"""
ä¿®å¤åçš„Cornellæ•°æ®é›†åŠ è½½å™¨
"""
import os
import glob
import numpy as np
import torch
from torch.utils.data import Dataset, DataLoader
from PIL import Image
import torchvision.transforms as transforms


class CornellGraspDataset(Dataset):
    """CornellæŠ“å–æ•°æ®é›† - ä¿®å¤ç‰ˆ"""

    def __init__(self, root_dir, split='train', train_ratio=0.7, val_ratio=0.15):
        self.root_dir = root_dir
        self.split = split
        self.transform = transforms.Compose([
            transforms.Resize((224, 224)),
            transforms.ToTensor(),
            transforms.Normalize(mean=[0.485, 0.456, 0.406],
                                 std=[0.229, 0.224, 0.225])
        ])

        # æŸ¥æ‰¾æ‰€æœ‰å›¾ç‰‡å’Œæ ‡æ³¨
        self.samples = self._load_dataset()

        # åˆ’åˆ†æ•°æ®é›†
        total_samples = len(self.samples)
        np.random.seed(42)
        indices = np.random.permutation(total_samples)

        train_end = int(total_samples * train_ratio)
        val_end = train_end + int(total_samples * val_ratio)

        if split == 'train':
            self.indices = indices[:train_end]
        elif split == 'val':
            self.indices = indices[train_end:val_end]
        else:  # test
            self.indices = indices[val_end:]

        print(f"  {split.capitalize()}: {len(self.indices)} samples")

    def _load_dataset(self):
        """åŠ è½½æ‰€æœ‰å›¾ç‰‡å’Œå¯¹åº”çš„æŠ“å–æ ‡æ³¨"""
        samples = []

        # æŸ¥æ‰¾æ‰€æœ‰RGBå›¾ç‰‡
        rgb_files = glob.glob(os.path.join(self.root_dir, "**", "pcd*r.png"),
                              recursive=True)

        print(f"  Found {len(rgb_files)} RGB images")

        for rgb_path in rgb_files:
            # æ„å»ºå¯¹åº”çš„æ ‡æ³¨æ–‡ä»¶è·¯å¾„
            base_name = os.path.basename(rgb_path).replace('r.png', '')
            grasp_path = rgb_path.replace('r.png', 'cpos.txt')

            if os.path.exists(grasp_path):
                # è§£ææŠ“å–æ¡†
                grasps = self._parse_grasp_file(grasp_path)
                if len(grasps) > 0:
                    samples.append({
                        'image_path': rgb_path,
                        'grasps': grasps
                    })

        print(f"  Loaded {len(samples)} samples with annotations")
        return samples

    def _parse_grasp_file(self, filepath):
        """
        è§£æCornellæŠ“å–æ ‡æ³¨æ–‡ä»¶
        æ¯ä¸ªæ–‡ä»¶åŒ…å«å¤šä¸ªæŠ“å–æ¡†ï¼Œæ¯ä¸ªæ¡†ç”±4ä¸ªç‚¹å®šä¹‰
        """
        grasps = []

        with open(filepath, 'r') as f:
            lines = f.readlines()

        # æ¯4è¡Œå®šä¹‰ä¸€ä¸ªæŠ“å–æ¡†
        for i in range(0, len(lines), 4):
            if i + 3 < len(lines):
                try:
                    # è§£æ4ä¸ªç‚¹çš„åæ ‡
                    points = []
                    for j in range(4):
                        coords = list(map(float, lines[i + j].strip().split()))
                        if len(coords) == 2:
                            points.append(coords)

                    if len(points) == 4:
                        # è®¡ç®—æŠ“å–ä¸­å¿ƒå’Œè§’åº¦
                        center, angle, width, height = self._compute_grasp_params(points)

                        grasps.append({
                            'center': center,
                            'angle': angle,
                            'width': width,
                            'height': height,
                            'points': points
                        })
                except:
                    continue

        return grasps

    def _compute_grasp_params(self, points):
        """
        ä»4ä¸ªç‚¹è®¡ç®—æŠ“å–å‚æ•°
        points: [[x1,y1], [x2,y2], [x3,y3], [x4,y4]]

        è¿”å›: center, angle, width, height
        """
        points = np.array(points)

        # è®¡ç®—ä¸­å¿ƒç‚¹
        center = points.mean(axis=0)

        # è®¡ç®—ä¸»è½´æ–¹å‘ï¼ˆè¿æ¥å¯¹è§’ç‚¹ï¼‰
        # å‡è®¾ç‚¹çš„é¡ºåºæ˜¯é€†æ—¶é’ˆæˆ–é¡ºæ—¶é’ˆ
        edge1 = points[1] - points[0]  # ç¬¬ä¸€æ¡è¾¹
        edge2 = points[2] - points[1]  # ç¬¬äºŒæ¡è¾¹

        # é€‰æ‹©è¾ƒé•¿çš„è¾¹ä½œä¸ºæŠ“å–æ–¹å‘
        len1 = np.linalg.norm(edge1)
        len2 = np.linalg.norm(edge2)

        if len1 > len2:
            grasp_direction = edge1
            width = len1
            height = len2
        else:
            grasp_direction = edge2
            width = len2
            height = len1

        # è®¡ç®—è§’åº¦ (å¼§åº¦è½¬è§’åº¦)
        angle = np.arctan2(grasp_direction[1], grasp_direction[0])
        angle = np.degrees(angle)

        # å½’ä¸€åŒ–è§’åº¦åˆ° [0, 180]
        angle = angle % 180

        return center, angle, width, height

    def __len__(self):
        return len(self.indices)

    def __getitem__(self, idx):
        actual_idx = self.indices[idx]
        sample = self.samples[actual_idx]

        # åŠ è½½å›¾ç‰‡
        image = Image.open(sample['image_path']).convert('RGB')
        orig_width, orig_height = image.size

        # éšæœºé€‰æ‹©ä¸€ä¸ªæŠ“å–æ¡†
        grasp = np.random.choice(sample['grasps'])

        # å½’ä¸€åŒ–åæ ‡åˆ° [0, 1]
        center_x = grasp['center'][0] / orig_width
        center_y = grasp['center'][1] / orig_height

        # å½’ä¸€åŒ–è§’åº¦åˆ° [0, 1]
        angle_normalized = grasp['angle'] / 180.0

        # åº”ç”¨å›¾åƒå˜æ¢
        if self.transform:
            image = self.transform(image)

        return {
            'image': image,
            'center_x': torch.tensor(center_x, dtype=torch.float32),
            'center_y': torch.tensor(center_y, dtype=torch.float32),
            'angle': torch.tensor(angle_normalized, dtype=torch.float32)
        }


def get_cornell_dataloaders(root_dir, batch_size=32, num_workers=0):
    """åˆ›å»ºCornellæ•°æ®é›†çš„DataLoader"""

    print(f"ğŸ“‚ Loading Cornell dataset from: {root_dir}")

    train_dataset = CornellGraspDataset(root_dir, split='train')
    val_dataset = CornellGraspDataset(root_dir, split='val')
    test_dataset = CornellGraspDataset(root_dir, split='test')

    train_loader = DataLoader(
        train_dataset,
        batch_size=batch_size,
        shuffle=True,
        num_workers=num_workers,
        pin_memory=True
    )

    val_loader = DataLoader(
        val_dataset,
        batch_size=batch_size,
        shuffle=False,
        num_workers=num_workers,
        pin_memory=True
    )

    test_loader = DataLoader(
        test_dataset,
        batch_size=batch_size,
        shuffle=False,
        num_workers=num_workers,
        pin_memory=True
    )

    return train_loader, val_loader, test_loader


# æµ‹è¯•ä»£ç 
if __name__ == '__main__':
    root_dir = r"D:\2025fighting\69_CSCI323_MSK\robotic-arm-grasping\cornell_dataset\datasets\oneoneliu\cornell-grasp\versions\1\01"

    print("=" * 60)
    print("Testing Fixed Cornell Dataset Loader")
    print("=" * 60)

    train_loader, val_loader, test_loader = get_cornell_dataloaders(
        root_dir,
        batch_size=4
    )

    # æµ‹è¯•ä¸€ä¸ªbatch
    print("\n" + "=" * 60)
    print("Testing first batch")
    print("=" * 60)

    batch = next(iter(train_loader))

    print(f"Image shape: {batch['image'].shape}")
    print(f"Center X range: [{batch['center_x'].min():.3f}, {batch['center_x'].max():.3f}]")
    print(f"Center Y range: [{batch['center_y'].min():.3f}, {batch['center_y'].max():.3f}]")
    print(f"Angle range: [{batch['angle'].min():.3f}, {batch['angle'].max():.3f}]")
    print(f"Angle (degrees): [{batch['angle'].min() * 180:.1f}Â°, {batch['angle'].max() * 180:.1f}Â°]")